{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "sys.path.append('../')\n",
    "rootPath = os.path.dirname(sys.path[0])\n",
    "sys.path.append(rootPath)\n",
    "import argparse\n",
    "import os.path as ops\n",
    "import cv2\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import json\n",
    "import time\n",
    "import argparse\n",
    "import math\n",
    "import json\n",
    "import glog as logger\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from tensorflow.python.ops import control_flow_ops\n",
    "from tensorflow.python.ops import math_ops\n",
    "from tensorflow.python.framework import dtypes\n",
    "from tensorflow.python.ops import random_ops\n",
    "\n",
    "from train_model.tools import evaluation_tools\n",
    "from train_model.crnn_model import crnn_model\n",
    "from train_model.config import model_config\n",
    "from train_model.data_provider import read_tfrecord\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
    "CFG = model_config.cfg\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 生成训练数据\n",
    "```\n",
    "!sh shell/generation_cn_tfrecord.sh  ~/sample_data/test.txt  0.2\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_num_class(char_dict_path):\n",
    "    \"\"\"\n",
    "    get the number of char classes automatically\n",
    "    :param char_dict_path: path for char_dictionary\n",
    "    \"\"\"\n",
    "    char_map_dict = json.load(open(char_dict_path, 'r',encoding='utf-8'))\n",
    "    if char_map_dict is None:\n",
    "        print(\"error\")\n",
    "    assert (isinstance(char_map_dict, dict) and 'char_map_dict is not a dict')\n",
    "    num_class = len(char_map_dict.keys())+1\n",
    "    return num_class\n",
    "\n",
    "def average_gradients(tower_grads):\n",
    "    \"\"\"Calculate the average gradient for each shared variable across all towers.\n",
    "    Note that this function provides a synchronization point across all towers.\n",
    "    Args:\n",
    "      tower_grads: List of lists of (gradient, variable) tuples. The outer list\n",
    "        is over individual gradients. The inner list is over the gradient\n",
    "        calculation for each tower.\n",
    "    Returns:\n",
    "       List of pairs of (gradient, variable) where the gradient has been averaged\n",
    "       across all towers.\n",
    "    \"\"\"\n",
    "    average_grads = []\n",
    "    for grad_and_vars in zip(*tower_grads):\n",
    "        # Note that each grad_and_vars looks like the following:\n",
    "        #   ((grad0_gpu0, var0_gpu0), ... , (grad0_gpuN, var0_gpuN))\n",
    "        grads = []\n",
    "        for g, _ in grad_and_vars:\n",
    "            # Add 0 dimension to the gradients to represent the tower.\n",
    "            expanded_g = tf.expand_dims(g, 0)\n",
    "\n",
    "            # Append on a 'tower' dimension which we will average over below.\n",
    "            grads.append(expanded_g)\n",
    "\n",
    "        # Average over the 'tower' dimension.\n",
    "        grad = tf.concat(grads, 0)\n",
    "        grad = tf.reduce_mean(grad, 0)\n",
    "\n",
    "        # Keep in mind that the Variables are redundant because they are shared\n",
    "        # across towers. So .. we will just return the first tower's pointer to\n",
    "        # the Variable.\n",
    "        v = grad_and_vars[0][1]\n",
    "        grad_and_var = (grad, v)\n",
    "        average_grads.append(grad_and_var)\n",
    "\n",
    "    return average_grads\n",
    "\n",
    "\n",
    "def compute_net_gradients(images, labels, net, optimizer=None, is_net_first_initialized=False):\n",
    "\n",
    "    _, net_loss = net.compute_loss(\n",
    "        inputdata=images,\n",
    "        labels=labels,\n",
    "        name='shadow_net',\n",
    "        reuse=is_net_first_initialized\n",
    "    )\n",
    "\n",
    "    if optimizer is not None:\n",
    "        grads = optimizer.compute_gradients(net_loss)\n",
    "    else:\n",
    "        grads = None\n",
    "\n",
    "    return net_loss, grads\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_shadownet_multi_gpu(dataset_dir_train, dataset_dir_val, weights_path, char_dict_path, save_path):\n",
    "    \"\"\"\n",
    "\n",
    "    :param dataset_dir:\n",
    "    :param weights_path:\n",
    "    :param char_dict_path:\n",
    "    :param ord_map_dict_path:\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    #caculdate num_class\n",
    "\n",
    "    NUM_CLASSES = get_num_class(char_dict_path)\n",
    "    print('---NUM_CLASSES------- ', NUM_CLASSES)\n",
    "\n",
    "    # prepare dataset\n",
    "    train_dataset = read_tfrecord.CrnnDataFeeder(\n",
    "        dataset_dir=dataset_dir_train, char_dict_path=char_dict_path, flags='train')\n",
    "\n",
    "    train_images, train_labels, train_images_paths = train_dataset.inputs(\n",
    "        batch_size=CFG.TRAIN.BATCH_SIZE)\n",
    "\n",
    "    val_dataset = read_tfrecord.CrnnDataFeeder(\n",
    "        dataset_dir=dataset_dir_val, char_dict_path=char_dict_path, flags='val')\n",
    "\n",
    "    val_images, val_labels, val_images_paths = val_dataset.inputs(\n",
    "        batch_size=CFG.TRAIN.BATCH_SIZE)\n",
    "\n",
    "\n",
    "    # set crnn net\n",
    "    shadownet = crnn_model.ShadowNet(\n",
    "        phase='train',\n",
    "        hidden_nums=CFG.ARCH.HIDDEN_UNITS,\n",
    "        layers_nums=CFG.ARCH.HIDDEN_LAYERS,\n",
    "        num_classes=NUM_CLASSES\n",
    "    )\n",
    "    shadownet_val = crnn_model.ShadowNet(\n",
    "        phase='test',\n",
    "        hidden_nums=CFG.ARCH.HIDDEN_UNITS,\n",
    "        layers_nums=CFG.ARCH.HIDDEN_LAYERS,\n",
    "        num_classes=NUM_CLASSES\n",
    "    )\n",
    "\n",
    "\n",
    "    # set average container\n",
    "    tower_grads = []\n",
    "    train_tower_loss = []\n",
    "    val_tower_loss = []\n",
    "    batchnorm_updates = None\n",
    "    train_summary_op_updates = None\n",
    "\n",
    "    # set lr\n",
    "    global_step = tf.Variable(0, name='global_step', trainable=False)\n",
    "    learning_rate = tf.train.exponential_decay(\n",
    "        learning_rate=CFG.TRAIN.LEARNING_RATE,\n",
    "        global_step=global_step,\n",
    "        decay_steps=CFG.TRAIN.LR_DECAY_STEPS,\n",
    "        decay_rate=CFG.TRAIN.LR_DECAY_RATE,\n",
    "        staircase=True)\n",
    "\n",
    "    # set up optimizer\n",
    "    optimizer = tf.train.MomentumOptimizer(learning_rate=learning_rate, momentum=0.9)\n",
    "\n",
    "    # set distributed train op\n",
    "    with tf.variable_scope(tf.get_variable_scope()):\n",
    "        is_network_initialized = False\n",
    "        for i in range(CFG.TRAIN.GPU_NUM):\n",
    "            with tf.device('/gpu:{:d}'.format(i)):\n",
    "                with tf.name_scope('tower_{:d}'.format(i)) as _:\n",
    "                    train_loss, grads = compute_net_gradients(\n",
    "                        train_images, train_labels, shadownet, optimizer,\n",
    "                        is_net_first_initialized=is_network_initialized)\n",
    "\n",
    "                    is_network_initialized = True\n",
    "\n",
    "                    # Only use the mean and var in the first gpu tower to update the parameter\n",
    "                    if i == 0:\n",
    "                        batchnorm_updates = tf.get_collection(tf.GraphKeys.UPDATE_OPS)\n",
    "                        train_summary_op_updates = tf.get_collection(tf.GraphKeys.SUMMARIES)\n",
    "\n",
    "                    tower_grads.append(grads)\n",
    "                    train_tower_loss.append(train_loss)\n",
    "                with tf.name_scope('validation_{:d}'.format(i)) as _:\n",
    "                    val_loss, _ = compute_net_gradients(\n",
    "                        val_images, val_labels, shadownet_val, optimizer,\n",
    "                        is_net_first_initialized=is_network_initialized)\n",
    "                    val_tower_loss.append(val_loss)\n",
    "\n",
    "    grads = average_gradients(tower_grads)\n",
    "    avg_train_loss = tf.reduce_mean(train_tower_loss)\n",
    "    avg_val_loss = tf.reduce_mean(val_tower_loss)\n",
    "\n",
    "    # Track the moving averages of all trainable variables\n",
    "    variable_averages = tf.train.ExponentialMovingAverage(\n",
    "        CFG.TRAIN.MOVING_AVERAGE_DECAY, num_updates=global_step)\n",
    "    variables_to_average = tf.trainable_variables() + tf.moving_average_variables()\n",
    "    variables_averages_op = variable_averages.apply(variables_to_average)\n",
    "\n",
    "    # Group all the op needed for training\n",
    "    batchnorm_updates_op = tf.group(*batchnorm_updates)\n",
    "    apply_gradient_op = optimizer.apply_gradients(grads, global_step=global_step)\n",
    "    train_op = tf.group(apply_gradient_op, variables_averages_op,\n",
    "                        batchnorm_updates_op)\n",
    "\n",
    "    # set tensorflow summary\n",
    "    \n",
    "    os.makedirs(save_path, exist_ok=True)\n",
    "    avg_train_loss_scalar = tf.summary.scalar(name='train_ctc_loss', tensor=avg_train_loss)\n",
    "    learning_rate_scalar = tf.summary.scalar(name='learning_rate', tensor=learning_rate)\n",
    "    avg_val_loss_scalar = tf.summary.scalar(name='val_ctc_loss', tensor=avg_val_loss)\n",
    "    train_merge_summary_op = tf.summary.merge([avg_train_loss_scalar, learning_rate_scalar])\n",
    "    val_merge_summary_op = tf.summary.merge([avg_val_loss_scalar])\n",
    "\n",
    "\n",
    "    # set tensorflow saver\n",
    "    saver = tf.train.Saver()\n",
    "    train_start_time = time.strftime('%Y-%m-%d-%H-%M-%S', time.localtime(time.time()))\n",
    "    model_name = 'shadownet_{:s}.ckpt'.format(str(train_start_time))\n",
    "    model_save_path = ops.join(save_path, model_name)\n",
    "\n",
    "    # set sess config\n",
    "    sess_config = tf.ConfigProto(device_count={'GPU': CFG.TRAIN.GPU_NUM}, allow_soft_placement=True)\n",
    "    sess_config.gpu_options.per_process_gpu_memory_fraction = CFG.TRAIN.GPU_MEMORY_FRACTION\n",
    "    sess_config.gpu_options.allow_growth = CFG.TRAIN.TF_ALLOW_GROWTH\n",
    "    sess_config.gpu_options.allocator_type = 'BFC'\n",
    "\n",
    "    summary_writer = tf.summary.FileWriter(save_path)\n",
    "\n",
    "    # Set the training parameters\n",
    "    #train_epochs = CFG.TRAIN.EPOCHS\n",
    "    train_epochs = 10\n",
    "\n",
    "    sess = tf.Session(config=sess_config)\n",
    "\n",
    "    summary_writer.add_graph(sess.graph)\n",
    "\n",
    "    with sess.as_default():\n",
    "        epoch = 0\n",
    "        tf.train.write_graph(graph_or_graph_def=sess.graph, logdir='',\n",
    "                             name='{:s}/shadownet_model.pb'.format(save_path))\n",
    "\n",
    "        if weights_path is None or not os.path.exists(weights_path):\n",
    "            logger.info('Training from scratch')\n",
    "            init = tf.global_variables_initializer()\n",
    "            sess.run(init)\n",
    "        else:\n",
    "            weights_path = tf.train.latest_checkpoint(weights_path)\n",
    "            logger.info('Restore model from last model checkpoint {:s}'.format(weights_path))\n",
    "            saver.restore(sess=sess, save_path=weights_path)\n",
    "            epoch = sess.run(tf.train.get_global_step())\n",
    "\n",
    "        train_cost_time_mean = []\n",
    "        val_cost_time_mean = []\n",
    "\n",
    "        while epoch < train_epochs:\n",
    "            epoch += 1\n",
    "            # training part\n",
    "            t_start = time.time()\n",
    "\n",
    "            _, train_loss_value, train_summary, lr = \\\n",
    "                sess.run(fetches=[train_op,\n",
    "                                  avg_train_loss,\n",
    "                                  train_merge_summary_op,\n",
    "                                  learning_rate])\n",
    "\n",
    "            if math.isnan(train_loss_value):\n",
    "                raise ValueError('Train loss is nan')\n",
    "\n",
    "            cost_time = time.time() - t_start\n",
    "            train_cost_time_mean.append(cost_time)\n",
    "\n",
    "            summary_writer.add_summary(summary=train_summary,\n",
    "                                       global_step=epoch)\n",
    "\n",
    "            # validation part\n",
    "            t_start_val = time.time()\n",
    "\n",
    "            val_loss_value, val_summary = \\\n",
    "                sess.run(fetches=[avg_val_loss,\n",
    "                                  val_merge_summary_op])\n",
    "\n",
    "            summary_writer.add_summary(val_summary, global_step=epoch)\n",
    "\n",
    "            cost_time_val = time.time() - t_start_val\n",
    "            val_cost_time_mean.append(cost_time_val)\n",
    "\n",
    "                \n",
    "            \n",
    "\n",
    "            if epoch % 2 ==0:\n",
    "                logger.info('lr={:4f} step:{:4d} train_loss={:9f}  val_loss= {:9f}' .format( \\\n",
    "                lr, epoch+1, train_loss_value, val_loss_value ))\n",
    "    saver.save(sess=sess, save_path=model_save_path, global_step=epoch)\n",
    "    print(\"step: {}  save path {}\".format(epoch, model_save_path))\n",
    "    sess.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "base_dir = '../output/'\n",
    "train_dataset_dir=base_dir + 'tfrecords/train'\n",
    "val_dataset_dir=base_dir + 'tfrecords/valid'\n",
    "char_dict_path=base_dir + 'text_data/char_map.json'\n",
    "weights_path=base_dir +'model_save/'\n",
    "tf.reset_default_graph()\n",
    "sess = train_shadownet_multi_gpu(\n",
    "            dataset_dir_train=train_dataset_dir,\n",
    "            dataset_dir_val=val_dataset_dir,\n",
    "            char_dict_path=char_dict_path,\n",
    "            weights_path=weights_path,\n",
    "            save_path=base_dir+'model_save'\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  进行测试 ocr-crnn-tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _sparse_matrix_to_list(sparse_matrix, char_map_dict_path=None):\n",
    "    \"\"\"\n",
    "    将矩阵拆分为list，参考：https://github.com/bai-shang/crnn_ctc_ocr.Tensorflow\n",
    "    :param sparse_matrix:\n",
    "    :param char_map_dict_path:\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    \n",
    "    indices = sparse_matrix.indices\n",
    "    values = sparse_matrix.values\n",
    "    dense_shape = sparse_matrix.dense_shape\n",
    "\n",
    "    # the last index in sparse_matrix is ctc blanck note\n",
    "    char_map_dict = json.load(open(char_map_dict_path, 'r',encoding='utf-8'))\n",
    "    if char_map_dict is None:\n",
    "        print(\"error\")\n",
    "    assert (isinstance(char_map_dict, dict) and 'char_map_dict is not a dict')\n",
    "\n",
    "    dense_matrix = len(char_map_dict.keys()) * np.ones(dense_shape, dtype=np.int32)\n",
    "    for i, indice in enumerate(indices):\n",
    "        dense_matrix[indice[0], indice[1]] = values[i]\n",
    "    string_list = []\n",
    "    for row in dense_matrix:\n",
    "        string = []\n",
    "        for val in row:\n",
    "            string.append(_int_to_string(val, char_map_dict))\n",
    "        string_list.append(''.join(s for s in string if s != '*'))\n",
    "    return string_list\n",
    "\n",
    "\n",
    "def _int_to_string(value, char_map_dict=None):\n",
    "\n",
    "    if char_map_dict is None:\n",
    "        print(\"error\")\n",
    "        #char_map_dict = json.load(open(FLAGS.char_map_json_file, 'r'))\n",
    "    assert (isinstance(char_map_dict, dict) and 'char_map_dict is not a dict')\n",
    "\n",
    "    for key in char_map_dict.keys():\n",
    "        if char_map_dict[key] == int(value):\n",
    "            return str(key)\n",
    "        elif len(char_map_dict.keys()) == int(value):\n",
    "            return \"\"\n",
    "    raise ValueError('char map dict not has {:d} value. convert index to char failed.'.format(value))\n",
    "\n",
    "\n",
    "def recognize_single_image(image_list, weights_path, char_dict_path):\n",
    "\n",
    "    tf.reset_default_graph()\n",
    "    char_map_dict = json.load(open(char_dict_path, 'r',encoding='utf-8'))\n",
    "    num_classes = len(char_map_dict) + 1\n",
    "    print('num_classes: ',  num_classes)\n",
    "    \n",
    "    \n",
    "    \n",
    "    inputdata = tf.placeholder(dtype=tf.float32,\n",
    "                               shape=[1, CFG.ARCH.INPUT_SIZE[1],\n",
    "                                      CFG.ARCH.INPUT_SIZE[0], CFG.ARCH.INPUT_CHANNELS],  # 宽度可变\n",
    "                               name='input')\n",
    "    \n",
    "    \n",
    "    net = crnn_model.ShadowNet(phase='test', \n",
    "                               hidden_nums=CFG.ARCH.HIDDEN_UNITS,\n",
    "                               layers_nums=CFG.ARCH.HIDDEN_LAYERS, \n",
    "                               num_classes=num_classes)\n",
    "    \n",
    "    inference_ret = net.inference(\n",
    "        inputdata=inputdata,\n",
    "        name='shadow_net',\n",
    "        reuse=False\n",
    "    )\n",
    "    \n",
    "    decodes, _ = tf.nn.ctc_beam_search_decoder(inputs=inference_ret, \n",
    "                                               sequence_length=int(CFG.ARCH.INPUT_SIZE[0] / 4) * np.ones(1),\n",
    "                                               merge_repeated=False, beam_width=10)\n",
    "     \n",
    "    # config tf saver\n",
    "    saver = tf.train.Saver()\n",
    "\n",
    "    # config tf session\n",
    "    sess_config = tf.ConfigProto(allow_soft_placement=True)\n",
    "    # sess_config.gpu_options.per_process_gpu_memory_fraction = CFG.TRAIN.GPU_MEMORY_FRACTION\n",
    "    # sess_config.gpu_options.allow_growth = CFG.TRAIN.TF_ALLOW_GROWTH\n",
    "\n",
    "    sess_config.gpu_options.allow_growth = True\n",
    "    sess = tf.Session(config=sess_config)\n",
    "    weights_path = tf.train.latest_checkpoint(weights_path)\n",
    "    print('weights_path: ', weights_path)\n",
    "    with sess.as_default():\n",
    "        saver.restore(sess=sess, save_path=weights_path)\n",
    "        \n",
    "        for image_path, label in image_list:\n",
    "            print(image_path)\n",
    "            image_name=image_path.split('/')[-1]\n",
    "            image = cv2.imread(image_path, cv2.IMREAD_COLOR)\n",
    "            image = cv2.resize(image, dsize=tuple(CFG.ARCH.INPUT_SIZE), interpolation=cv2.INTER_LINEAR)\n",
    "            image_vis = image\n",
    "            image = np.array(image, np.float32) / 127.5 - 1.0\n",
    "            \n",
    "            \n",
    "            \n",
    "            seq_len = np.array([image.shape[1] / 4], dtype=np.int32)\n",
    "#             print('seq_len ', seq_len)\n",
    "            preds = sess.run(decodes, feed_dict={inputdata: [image]})\n",
    "            preds = _sparse_matrix_to_list(preds[0], char_dict_path)\n",
    "            print('Label: {:25s} Predict: [{:s}]'.format(label, preds[0]))\n",
    "            \n",
    "            plt.figure('CRNN Model Demo')\n",
    "            plt.imshow(image_vis[:, :, (2, 1, 0)])\n",
    "            plt.show()\n",
    "\n",
    "    sess.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_dir = '../output/'\n",
    "train_file = base_dir +  'text_data/train_labels.txt'\n",
    "images_base_dir = base_dir + 'images/train/'\n",
    "weights_path= base_dir + 'model_save/'\n",
    "char_dict_path=base_dir + 'text_data/char_map.json'\n",
    "tf.reset_default_graph()\n",
    "\n",
    "\n",
    "with open(train_file, 'r') as f1:\n",
    "    linelist = f1.readlines()\n",
    "    \n",
    "image_list = []   \n",
    "for i in range(5):\n",
    "    image_path = images_base_dir + linelist[i].split(' ')[0]\n",
    "    image_list.append((image_path, linelist[i].split(' ')[1].replace('\\r','').replace('\\n','').replace('\\t','')))\n",
    "\n",
    "\n",
    "for path, label in image_list:\n",
    "    print(path, label)\n",
    "    \n",
    "recognize_single_image(image_list,weights_path, char_dict_path) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:amazonei_tensorflow_p36]",
   "language": "python",
   "name": "conda-env-amazonei_tensorflow_p36-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
